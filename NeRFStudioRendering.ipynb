{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datamodule import ExampleDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams:\n",
    "    def __init__(self, datadir, img_shape, vol_shape, batch_size, seed) -> None:\n",
    "        self.datadir = datadir\n",
    "        self.img_shape = img_shape\n",
    "        self.vol_shape = vol_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "\n",
    "# hparams = parser.parse_args()\n",
    "hparams = Hparams(\n",
    "    datadir='/home/quantm/data',\n",
    "    img_shape=256, \n",
    "    vol_shape=256, \n",
    "    batch_size=4, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image3d_folders = [os.path.join(hparams.datadir, \"Visualization/image3d\"),]\n",
    "train_image2d_folders = [os.path.join(hparams.datadir, \"Visualization/image2d\"),]\n",
    "val_image3d_folders = [os.path.join(hparams.datadir, \"Visualization/image3d\"),]\n",
    "val_image2d_folders = [os.path.join(hparams.datadir, \"Visualization/image2d\"),]\n",
    "test_image3d_folders = [os.path.join(hparams.datadir, \"Visualization/image3d\"),]\n",
    "test_image2d_folders = [os.path.join(hparams.datadir, \"Visualization/image2d\"),]\n",
    "\n",
    "datamodule = ExampleDataModule(\n",
    "    train_image3d_folders=train_image3d_folders,\n",
    "    train_image2d_folders=train_image2d_folders,\n",
    "    val_image3d_folders=val_image3d_folders,\n",
    "    val_image2d_folders=val_image2d_folders,\n",
    "    test_image3d_folders=test_image3d_folders,\n",
    "    test_image2d_folders=test_image2d_folders,\n",
    "    img_shape=hparams.img_shape,\n",
    "    vol_shape=hparams.vol_shape,\n",
    "    batch_size=hparams.batch_size,\n",
    ")\n",
    "datamodule.setup(seed=hparams.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nerfstudio.cameras.cameras import Cameras, CameraType\n",
    "from nerfstudio.utils import plotly_utils as vis\n",
    "import plotly.graph_objects as go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cx = 20.0\n",
    "# cy = 10.0\n",
    "# fx = 20.0\n",
    "# fy = 20.0\n",
    "\n",
    "# c2w = torch.eye(4)[None, :3, :]\n",
    "\n",
    "# camera = Cameras(fx=fx, fy=fy, cx=cx, cy=cy, camera_to_worlds=c2w, camera_type=CameraType.PERSPECTIVE)\n",
    "# fig = vis.vis_camera_rays(camera)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 3\n",
    "# near_plane = 1\n",
    "# far_plane = 3\n",
    "\n",
    "# ray_bundle = camera.generate_rays(camera_indices=0)\n",
    "\n",
    "# bins = torch.linspace(near_plane, far_plane, num_samples + 1)[..., None]\n",
    "# ray_samples = ray_bundle.get_ray_samples(bin_starts=bins[:-1, :], bin_ends=bins[1:, :])\n",
    "\n",
    "# vis_rays = vis.get_ray_bundle_lines(ray_bundle, color=\"teal\", length=far_plane)\n",
    "\n",
    "# fig = go.Figure(\n",
    "#     data=[\n",
    "#         vis_rays, \n",
    "#         vis.get_frustum_points(ray_samples.frustums)\n",
    "#     ], \n",
    "#     # layout=webdocs_layout\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nerfstudio.model_components import renderers\n",
    "\n",
    "# num_samples = 10\n",
    "\n",
    "# rgb_samples = torch.ones((3, num_samples, 3))\n",
    "# weights = torch.ones((3, num_samples, 1))\n",
    "# weights /= torch.sum(weights, dim=-2, keepdim=True)\n",
    "\n",
    "# rgb_renderer = renderers.RGBRenderer()\n",
    "\n",
    "# rgb = rgb_renderer(rgb=rgb_samples, weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ModelConfig' has no attribute 'collider_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 82\u001b[0m\n\u001b[1;32m     77\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m: rgb,\n\u001b[1;32m     79\u001b[0m         }\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs    \n\u001b[0;32m---> 82\u001b[0m scalar_modle \u001b[38;5;241m=\u001b[39m \u001b[43mScalarModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelConfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscene_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSceneBox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/models/base_model.py:84\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, config, scene_box, num_train_data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollider \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# populate the modules\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# to keep track of which device the nn.Module is on\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m, in \u001b[0;36mScalarModel.populate_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpopulate_modules\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the fields and modules.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# scene_contraction = SceneContraction(order=float(\"inf\"))\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Fields\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield \u001b[38;5;241m=\u001b[39m ScalarField()\n",
      "File \u001b[0;32m~/anaconda3/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/models/base_model.py:106\u001b[0m, in \u001b[0;36mModel.populate_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# default instantiates optional modules that are common among many networks\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# NOTE: call `super().populate_modules()` in subclasses\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39menable_collider:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollider_params\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollider \u001b[38;5;241m=\u001b[39m NearFarCollider(\n\u001b[1;32m    108\u001b[0m         near_plane\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcollider_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnear_plane\u001b[39m\u001b[38;5;124m\"\u001b[39m], far_plane\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcollider_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfar_plane\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    109\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ModelConfig' has no attribute 'collider_params'"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from nerfstudio.cameras.rays import RayBundle, RaySamples\n",
    "from nerfstudio.data.scene_box import SceneBox\n",
    "from nerfstudio.field_components.activations import trunc_exp\n",
    "from nerfstudio.fields.base_field import Field\n",
    "from nerfstudio.models.base_model import Model, ModelConfig\n",
    "\n",
    "from nerfstudio.model_components.ray_samplers import ProposalNetworkSampler, UniformSampler\n",
    "from nerfstudio.model_components.renderers import AccumulationRenderer, DepthRenderer, NormalsRenderer, RGBRenderer\n",
    "from nerfstudio.model_components.scene_colliders import NearFarCollider\n",
    "from nerfstudio.model_components.shaders import NormalsShader\n",
    "\n",
    "class ScalarField(Field):\n",
    "    def __init__(\n",
    "        self,\n",
    "        aabb: Tensor,\n",
    "        implementation: Literal[\"tcnn\", \"torch\"] = \"torch\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"aabb\", aabb)\n",
    "\n",
    "    def get_density(self, ray_samples: RaySamples) -> Tuple[Tensor, None]:\n",
    "        positions = SceneBox.get_normalized_positions(ray_samples.frustums.get_positions(), self.aabb)\n",
    "        # Make sure the tcnn gets inputs between 0 and 1.\n",
    "        selector = ((positions > 0.0) & (positions < 1.0)).all(dim=-1)\n",
    "        positions = positions * selector[..., None]\n",
    "        positions_flat = positions.view(-1, 3)\n",
    "\n",
    "        density = density * selector[..., None]\n",
    "        return density, None\n",
    "\n",
    "    def get_outputs(self, ray_samples: RaySamples, density_embedding: Optional[Tensor] = None) -> dict:\n",
    "        return {}\n",
    "    \n",
    "class ScalarModel(Model):\n",
    "    config: ModelConfig\n",
    "\n",
    "    def populate_modules(self):\n",
    "        \"\"\"Set the fields and modules.\"\"\"\n",
    "        super().populate_modules()\n",
    "        # scene_contraction = SceneContraction(order=float(\"inf\"))\n",
    "\n",
    "        # Fields\n",
    "        self.field = ScalarField()\n",
    "        \n",
    "        # Samplers\n",
    "        self.sampler = UniformSampler(single_jitter=self.config.use_single_jitter)\n",
    "        # Colliders\n",
    "\n",
    "        # Renderers\n",
    "        self.renderer_rgb = RGBRenderer(background_color=self.config.background_color)\n",
    "        \n",
    "        # Losses\n",
    "\n",
    "        # Metrics\n",
    "\n",
    "    def get_outputs(self, ray_bundle: RayBundle):\n",
    "        # apply the camera optimizer pose tweaks\n",
    "        if self.training:\n",
    "            self.camera_optimizer.apply_to_raybundle(ray_bundle)\n",
    "        ray_samples: RaySamples\n",
    "        ray_samples, weights_list, ray_samples_list = self.proposal_sampler(ray_bundle, density_fns=self.density_fns)\n",
    "        field_outputs = self.field.forward(ray_samples, compute_normals=self.config.predict_normals)\n",
    "        if self.config.use_gradient_scaling:\n",
    "            field_outputs = scale_gradients_by_distance_squared(field_outputs, ray_samples)\n",
    "\n",
    "        weights = ray_samples.get_weights(field_outputs[FieldHeadNames.DENSITY])\n",
    "        weights_list.append(weights)\n",
    "        ray_samples_list.append(ray_samples)\n",
    "\n",
    "        rgb = self.renderer_rgb(rgb=field_outputs[FieldHeadNames.RGB], weights=weights)\n",
    "        \n",
    "        outputs = {\n",
    "            \"rgb\": rgb,\n",
    "        }\n",
    "        return outputs    \n",
    "    \n",
    "scalar_modle = ScalarModel(\n",
    "    config=ModelConfig,\n",
    "    scene_box=SceneBox, \n",
    "    num_train_data=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
